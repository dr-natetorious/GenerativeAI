# Foundational Models 

## On the Opportunities and Risks of Foundation Models (2022)

Bommasani, R (2022). On the Opportunities and Risks of Foundation Models. https://arxiv.org/abs/2108.07258. [OpportunitiesRisks](OpportunitiesRisks.pdf).

> **Foundation models**. Foundation models have taken shape most strongly in NLP, so we focus our story there for the moment. That said, much as deep learning was popularized in computer vision but exists beyond it, we understand foundation models as a general paradigm of AI, rather than specific to NLP in any way. By the end of 2018, the field of NLP was about to undergo another seismic change, marking the beginning of the era of foundation models. **On a technical level,foundation models are enabled by transfer learning [Thrun 1998] and scale**. The idea of transfer learning is to take the “knowledge” learned from one task (e.g., object recognition in images) and apply it to another task (e.g., activity recognition in videos). Within deep learning, pretraining is the dominant approach to transfer learning: a model is trained on a surrogate task (often just as a means to an end) and then adapted to the downstream task of interest via fine-tuning. Transfer learning is what makes foundation models possible, but scale is what makes them powerful. Scale required three ingredients: (i) improvements in computer hardware — e.g., GPU throughput and memory have increased 10× over the last four years (§4.5: systems); (ii) the development of the Transformer model architecture [Vaswani et al. 2017] that leverages the parallelism of the hardware to train much more expressive models than before (§4.1: modeling); and (iii) the availability of much more training data.

### What challenges do foundational models introduce

There are only a handful of foundational models because they are expensive and complex to create. This means that a lot of research builds upon these artifacts and implicitly inherits and faults or limitations. However, that also means that any improvements into the base system are potentially far reaching.

The authors refer to the phenomenom as `homogenization` as everything is converging to only a few specialized implementations. They also talk about the `emergence` of implicit behaviors that come from FMs versus explicit constructs.

### Why do the authors call these FM?

> We introduce the term foundation models to fill a void in describing the paradigm shift we are witnessing; we briefly recount some of our reasoning for this decision. Existing terms (e.g., pretrained model, self-supervised model) partially capture the technical dimension of these models, **but fail to capture the significance of the paradigm shift in an accessible manner for those beyond machine learning. In particular, foundation model designates a model class that are distinctive in their sociological impact and how they have conferred a broad shift in AI research and deployment**. In contrast, forms of pretraining and self-supervision that technically foreshadowed foundation models fail to clarify the shift in practices we hope to highlight. Additionally, while many of the iconic foundation models at the time of writing are language models, the **term language model is simply too narrow for our purpose**: as we describe, the scope of foundation models goes well beyond language

### What sociological impact is there

> A recurring theme is that it is easier to reason about the social impact of specific systems deployed to specific users than it is to reason about the social impact of foundation models, which could be adapted to any number of unforeseen downstream systems.[...] Foundation models have demonstrated raw potential, but we are still in the early days. Despite their deployment into the real world, these models are very much research prototypes that are poorly understood.

The authors overarching concern is that foundational models will touch every industry and concept globally. However, there is minimal research into the controls and protections that influence their vocabulary. For instance, if the system has never encountered a _black swan_ there's no mechanism to recommend it to the derived models.

There's also certain risks that come from the training data being random internet text. For example, foundational models like GPT are trained on Reddit outbound links. This design means that ChatGPT has likely read 4Chan and similar cesspools. While content moderation constructs exist to mitigate inappropriate responses there's inherient risks of users bypassing those protections. However, this argument is flawed. Most Fortune-500 companies have phone support staff that know a few curse words. Should we remove them from the system too? 

### What capabilities does FM offer

> Foundation models acquire various capabilities that can power applications. We have chosen to discuss five potential capabilities: the ability to process different modalities (e.g., language, vision), to affect the physical world (robotics), to perform reasoning, and to interact with humans (interaction).

- **§2.1: Language**. NLP as a field has blazed the trail for foundation models. While these models dominate standard benchmarks, there is a clear gap between the capabilities these models acquire currently and those that characterize language as a complex system for human communication and thought. In response to this, we emphasize the full range of linguistic variation (e.g., different styles, dialects, languages), which poses an opportunity and challenge given some variants are data-limited. Further, child language acquisition is more sample efficient than the training of foundation models; we examine how signals beyond text and grounding may help to bridge this gap. Both of these characteristics of language provide clear directions for future foundation models research.
- **§2.2: Vision**. Computer vision led the adoption of deep learning in AI [Russakovsky et al. 2015],demonstrating that models pretrained on large annotated datasets can transfer to numerous downstream settings. Now, pretraining on web-scale raw data instead of curated datasets, foundation models are on the rise in computer vision [e.g., Radford et al. 2021]. These models have shown promising results for standard tasks in the field, like image classification and object detection, and training on multimodal and embodied data beyond images may enable progress on significant challenges (e.g., 3D geometric and physical understanding, commonsense reasoning). We also discuss some of the key challenges in modeling (e.g., the ability to scale effectively to videos) and evaluation (e.g., the measurement of higher-order capabilities) along with the applications (e.g., ambient intelligence for healthcare) and societal considerations (e.g., surveillance) that will determine the impact of foundation models for computer vision going forward. 
- **§2.3: Robotics**. A longstanding goal of robotics research is to develop “generalist” robots capable of performing myriad tasks across physically diverse environments. Unlike language and vision, which have led the way with foundation models both due to the abundance of raw data to train these models on and the availability of virtual applications to apply these models to, robotics faces fundamental challenges due to being anchored to the physical world. The principal challenge in developing new types of foundation models for robotics — different in nature than their language and vision counterparts — is acquiring sufficient data of the right form that is conducive to learning: we explore how plentiful data (e.g., generic videos of humans, amongst others) that is not specific to particular environments and across modalities (e.g., language, vision) may help to bridge this gap. These new robotic foundation models could allow for easier task specification and learning, ushering in new applications (e.g., better robotic assistance for household tasks) and heightening the importance of robustness and safety (e.g., formal safety evaluation).
- **§2.4: Reasoning and search**. Reasoning and search problems such as theorem proving and program synthesis have been long-standing challenges in AI. The combinatorial search space renders traditional search-based methods intractable. However, humans are known to operate intuitively even in the most mathematical of domains [Lakoff and Núñez 2000], and indeed existing work such as AlphaGo have already shown that deep neural networks can be effective in guiding the search space. But humans also transfer knowledge across tasks, facilitating much more efficient adaptation and the ability to reason more abstractly. Foundation models offer the possibility of closing this gap: their multi-purpose nature along with their strong generative and multimodal capabilities offer new leverage for controlling the combinatorial explosion inherent to search.
- **§2.5: Interaction**. Foundation models show clear potential to transform the developer and user experience for AI systems: foundation models lower the difficulty threshold for prototyping and building AI applications due to their sample efficiency in adaptation, and raise the ceiling for novel user interaction due to their multimodal and generative capabilities. This provides a synergy we encourage going forward: developers can provide applications that better fit the user’s needs and values, while introducing far more dynamic forms of interaction and opportunities for feedback. 
- **§2.6: Philosophy of understanding**. What could a foundation model come to understand about the data it is trained on? Focusing on the case of natural language, we identify different positions on the nature of understanding and explore their relevance for our central question. Our tentative conclusion is that skepticism about the capacity of future foundation models to understand natural language may be premature, especially where the models are trained on multi-modal data.

### What language limitations existin within language models

Large language models learn the probability token represent the masked token in a sentence. Since tokens represent a handful of charcters this means that LLMs cannot predict dialects and derived languages beyond its training data. For example, there's a extensive training data for English, French, and Spanish. However, there's minimal information for Fula-- a west African language with 65M speakers.

Even within English these limiations become appearant when considering the _media_ of exchange. The authors point out that even formal versus informal versus written conversations has distinct structures that influence the LLMs calculus.

> Foundation models like GPT-3 are trained on around three to four orders of magnitude more language data than most humans will ever hear or read, and certainly much more than children have been exposed to by the time they are mostly linguistically competent.
